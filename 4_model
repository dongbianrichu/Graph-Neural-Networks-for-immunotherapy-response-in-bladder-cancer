import sys
import os
import pandas as pd
import numpy as np
import tqdm
import torch
from torch_geometric.loader import DataLoader
from sklearn.metrics import roc_auc_score
from utils import seed_torch
from submodel import Pathway_Score
import random
from captum.attr import IntegratedGradients


###############################################################################
#                                                                             #
#               　　　　　　　  Ｄefine metrics     　　                         #
#                                                                             #
###############################################################################
def get_auc(outputs, labels):
    auc = roc_auc_score(labels, outputs)
    return auc


def get_acc(output, target):
    output = torch.sigmoid(output) >= 0.5
    target = target == 1.0
    return torch.true_divide((target == output).sum(dim=0), output.size(0)).item()


###############################################################################
#                                                                             #
#               　　　　　　　  Get sample's label  　　                         #
#                                                                             #
###############################################################################
def get_labels(dataset, df_os_1):
    real_labels = []
    for smp, data in dataset.items():
        if smp in df_os_1.id.values:
            real_labels.append(0.0)
        else:
            real_labels.append(1.0)
    real_labels = torch.tensor(real_labels)

    return real_labels



###############################################################################
#                                                                             #
#               　　　　　　　  Split: Train and Test data                      #
#                                                                             #
###############################################################################

def split_dataset(dataset, df_os_1, df_os_2='N', test_perc=0.2):
    seed_torch()
    total_smp = list(dataset.keys())
    group1_smp = df_os_1.id.to_list()
    group2_smp = df_os_2.id.to_list()
    group1_smp_test = list(np.random.choice(group1_smp, round(len(group1_smp)*test_perc), replace=False))
    group1_smp_train = [ i for i in group1_smp if i not in group1_smp_test]

    group2_smp_test = list(np.random.choice(group2_smp, round(len(group2_smp)*test_perc), replace=False))
    group2_smp_train = [ i for i in group2_smp if i not in group2_smp_test]

    # train_dataset
    train_dataset = {}
    train_labels = []
    labels_ = group1_smp_train + group2_smp_train
    random.shuffle(labels_)
    for l in labels_:
        train_dataset[l] = dataset[l]
        if l in group1_smp_train:
            train_labels.append(0.0)
        else:
            train_labels.append(1.0)
    train_labels = torch.tensor(train_labels)

    # test_dataset
    test_dataset = {}
    test_labels = []
    labels_ = group1_smp_test + group2_smp_test
    random.shuffle(labels_)
    for l in labels_:
        test_dataset[l] = dataset[l]
        if l in group1_smp_test:
            test_labels.append(0.0)
        else:
            test_labels.append(1.0)
    test_labels = torch.tensor(test_labels)

    return train_labels, train_dataset, test_labels, test_dataset


def split_dataset_fold(dataset, df_os_1, df_os_2, folds=5 ,test_fold=1):
    if test_fold > folds:
        print('error: Test fold should be less than folds.\n')
        sys.exit(0)
    group1_smp = df_os_1.id.to_list()
    group2_smp = df_os_2.id.to_list()
    seed_torch(42)
    random.shuffle(group1_smp)
    seed_torch(42)
    random.shuffle(group2_smp)
    group1_smp_ = group1_smp + group1_smp
    group2_smp_ = group2_smp + group2_smp
    group1_step = round(len(group1_smp) / folds)
    group2_step = round(len(group2_smp) / folds)

    group1_smp_test = group1_smp_[group1_step*(test_fold-1): group1_step*test_fold]
    group1_smp_train = [ i for i in group1_smp if i not in group1_smp_test]

    group2_smp_test = group2_smp_[group2_step*(test_fold-1): group2_step*test_fold]
    group2_smp_train = [ i for i in group2_smp if i not in group2_smp_test]

    # train_dataset
    train_dataset = {}
    train_labels = []
    labels_ = group1_smp_train + group2_smp_train
    random.shuffle(labels_)
    for l in labels_:
        train_dataset[l] = dataset[l]
        if l in group1_smp_train:
            train_labels.append(0.0)
        else:
            train_labels.append(1.0)
    train_labels = torch.tensor(train_labels)

    # test_dataset
    test_dataset = {}
    test_labels = []
    labels_ = group1_smp_test + group2_smp_test
    random.shuffle(labels_)
    for l in labels_:
        test_dataset[l] = dataset[l]
        if l in group1_smp_test:
            test_labels.append(0.0)
        else:
            test_labels.append(1.0)
    test_labels = torch.tensor(test_labels)

    return train_labels, train_dataset, test_labels, test_dataset



###############################################################################
#                                                                             #
#               　　　　　　　  Define Model        　　                         #
#                                                                             #
###############################################################################
# class Model(torch.nn.Module):
#     def __init__(self, submodel, dataset):
#         super(Model, self).__init__()
#         self.submodel = submodel
#         self.lin = torch.nn.Sequential(
#             torch.nn.Linear(len(dataset[list(dataset.keys())[0]]) + 2, 256) , # Two-class task
#             torch.nn.ReLU(),
#             # torch.nn.BatchNorm1d(128),
#             # torch.nn.Dropout(p=0.4),
#             torch.nn.Linear(256, 128),
#             torch.nn.Dropout(p=0.4),
#             torch.nn.ReLU(),
#             torch.nn.Linear(128, 32),
#             torch.nn.ReLU(),
#             torch.nn.Linear(32, 2),
#             torch.nn.Softmax(dim=0)
#         )
    
#     def forward(self, data, device, cli_features):   
#         """
#         cli_features: a list, value is tensor
#         """     
#         pathway_score = []  # save pathway score

#         loader = DataLoader(data, batch_size=60, shuffle=False)
#         for dat in loader:
#             dat = dat.to(device)
#             x = self.submodel(dat)
#             pathway_score.append(x)

#         pathway_score += cli_features
#         x = torch.cat(pathway_score, dim=0)
#         x = self.lin(x)
#         return x

class Model(torch.nn.Module):
    def __init__(self, submodel, dataset):
        super(Model, self).__init__()
        self.submodels = torch.nn.ModuleList()
        for _ in range(927):
            self.submodels.append(Pathway_Score())
        self.lin = torch.nn.Sequential(
            torch.nn.Linear(len(dataset[list(dataset.keys())[0]]), 512) , # Two-class task
            torch.nn.ReLU(),
            torch.nn.Linear(512, 256),
            torch.nn.Dropout(p=0.4),
            torch.nn.ReLU(),
            torch.nn.Linear(256, 128),
            torch.nn.ReLU(),
            torch.nn.Linear(128, 32),
            torch.nn.ReLU(),
            torch.nn.Linear(32, 2),
            torch.nn.Softmax(dim=0)
        )
    
    def forward(self, data, device):
        """

        """     
        pathway_score = []  # save pathway score
        loader = DataLoader(data, batch_size=10, shuffle=False)
        i = 0
        for dat in loader:
            dat = dat.to(device)
            x = self.submodels[i](dat)
            pathway_score.append(x)
            i += 1
        x = torch.cat(pathway_score, dim=0).to(torch.device("cuda:0" if torch.cuda.is_available() else "cpu"))
        x = self.lin(x)
        return x

###############################################################################
#                                                                             #
#               　　　　　　　  Define Train        　　                         #
#                                                                             #
###############################################################################

def train(train_labels, train_dataset, test_labels, test_dataset, minibatch=50):
    ## forward per pathway for one sample
    out_probs = []  # model output
    real_label = []  # train labels
    loss_all = []
    auc_all = [] 
    acc_all = []
    idx = 0

    for smp, data in tqdm.tqdm(train_dataset.items()):
              # forward
        out_probs.append(model(data, device=device))
        real_label.append(train_labels[idx])

        # backward
        idx += 1
        if idx % minibatch == 0 or smp==list(train_dataset.keys())[-1]:
            model.train()
            optimizer.zero_grad()

            ## get batch loss 
            real_label = torch.tensor(real_label)
            out_probs = torch.cat(out_probs, dim=0).reshape(-1,2).cpu()
            loss = criterion(out_probs, real_label.type(torch.long))
            loss.backward()
            optimizer.step()

            # output batch loss
            loss_all.append(loss.item())

            # output batch auc
            auc = get_auc(out_probs.detach().numpy()[:,1], real_label)
            auc_all.append(auc)

            # output batch acc
            out_classes = np.argmax(out_probs.detach().numpy(), axis=1)
            acc = sum(out_classes == real_label.detach().numpy()) / len(real_label)
            acc_all.append(acc)

            # reset out_probs and real_label
            out_probs = []
            real_label = []
    
    # validation
    test_auc, test_acc = test_func(test_labels, test_dataset)
    train_auc, train_acc = test_func(train_labels, train_dataset)
    print('Fold: ', fold)
    # print('Epoch: {:03d}, Loss: {:.5f};  Train_Acc: {:.5f}, Train_Auc: {:.5f}, Test_Acc: {:.5f}, Test_Auc: {:.5f}\n'.format(
    #     epoch, np.mean(loss_all), np.mean(acc_all), np.mean(auc_all), test_acc, test_auc))
    print('Epoch: {:03d}, Loss: {:.5f};  Train_Acc: {:.5f}, Train_Auc: {:.5f}, Test_Acc: {:.5f}, Test_Auc: {:.5f}\n'.format(
        epoch, np.mean(loss_all), train_acc, train_auc, test_acc, test_auc))

    # output training log
    with open(save_log, 'a') as F:
        F.writelines('Fold: {:02d}, Epoch: {:03d}, Loss: {:.5f};  Train_Acc: {:.5f}, Train_Auc: {:.5f}, Test_Acc: {:.5f}, Test_Auc: {:.5f}\n'.format(
            fold, epoch, np.mean(loss_all), train_acc, train_auc, test_acc, test_auc))

    return model


###############################################################################
#                                                                             #
#               　　　　　　　  Define Test         　　                         #
#                                                                             #
###############################################################################

def test_func(test_labels, test_dataset):
    out_probs = []
    for smp, data in tqdm.tqdm(test_dataset.items()):
        model.eval()
        with torch.no_grad():
            out_probs.append(model(data, device=device))

    out_probs = torch.cat(out_probs, dim=0).reshape(-1,2).cpu()

    # output batch auc
    auc = get_auc(out_probs.detach().numpy()[:,1], test_labels)

    # output batch acc
    out_classes = np.argmax(out_probs.detach().numpy(), axis=1)
    acc = sum(out_classes == test_labels.detach().numpy()) / len(test_labels)

    return auc, acc


###############################################################################
#                                                                             #
#               　　　　　　　  Define IG           　　                         #
#                                                                             #
###############################################################################

def ig(path_model, test_labels, test_dataset, figname, output):
    print('[IG]...\n')
    tb = pd.read_table(path_cli)
    tb = tb.set_index('id')
    model = torch.load(path_model)
    model.to(torch.device("cuda:0" if torch.cuda.is_available() else "cpu"))
    model.eval()
    S = []
    smps = ['Pathway', 'Score_median', 'Score_zscore']
    with torch.no_grad():
        for smp, data in tqdm.tqdm(test_dataset.items()):
            smps.append(smp)
            i = 0
            for dat in data:
                dat = dat.cuda()
                S.append(float(model.submodels[i](dat).cpu().detach().numpy()))
                i += 1

##  input_tensor_ = torch.tensor(S, dtype=torch.float32).reshape(-1, 857).to(torch.device("cuda:0" if torch.cuda.is_available() else "cpu"))
    input_tensor_ = torch.tensor(S, dtype=torch.float32).reshape(-1, 927).to(torch.device("cuda:0" if torch.cuda.is_available() else "cpu"))
    input_tensor_.requires_grad_()
    net = model.lin
    ig = IntegratedGradients(net)

    # run ig
    attr, delta = ig.attribute(input_tensor_, target=1, return_convergence_delta=True)
    attr = attr.cpu().detach().numpy()

    # get features
    df_pathway = pd.read_table('Dataset\\IMvigor210_pathway_reactome_ssgsea.pt.pathway_names.txt')
    features = np.array(df_pathway.pathway.to_list())

    # stats
    df_attr = pd.DataFrame(attr).T
    df_median = pd.DataFrame(df_attr.T.median())
    df_median.columns = ['median']
    df_zscore = (df_median - df_median.mean()) / df_median.std()
    df_zscore.columns = ['zscore']
    df_feature = pd.DataFrame(features)
    df_feature.columns = ['feature']
    df_attr = pd.DataFrame(attr).T
    df_attr_out = pd.concat([df_feature, df_median, df_zscore, df_attr], axis=1)
    df_attr_out['sort_'] = df_attr_out['median'].map(abs)
    df_attr_out = df_attr_out.sort_values('sort_', ascending=False)
    df_attr_out = df_attr_out.drop(columns=['sort_']).reset_index(drop=True)
    df_attr_out.columns = smps
    df_attr_out.to_csv(output, index=False, sep='\t')

    # plot
    # print(df_attr_out)
    # df_plot = df_attr_out[df_attr_out.Score_zscore.abs() > 1.5]
    # fig, ax = plt.subplots(1,1,figsize=(8,6))
    # plt.barh(df_plot.Pathway, df_plot.Score_zscore)
    # ax.invert_yaxis()
    # plt.xlabel('Feature importance')
    # plt.savefig(figname, bbox_inches = 'tight')


if __name__ == '__main__':
    # set seed
    seed_torch(1024)

    train_step = True
    # Get configures
    #config = get_config(sys.argv[1])
    ## device
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    ## project root dir
    project_root_dir = './'
    ## dataset file path
    path_dataset = os.path.join(project_root_dir, 'Dataset/pathway_reactome_ssgsea.pt')
    ## cilical file path
    path_cli = os.path.join(project_root_dir, 'Dataset/IMvigor210_clinical.txt')
    ## submodel file path
    path_submodel = os.path.join(project_root_dir,  'Model/submodel_v1.pt')
    ## KM figname
    km_fig = os.path.join(project_root_dir, 'Results/KM_survival.pdf')
    ## KM group1
    km_group1 = os.path.join(project_root_dir, 'Results/group1.tsv')
    ## KM group2
    km_group2 = os.path.join(project_root_dir, 'Results/group2.tsv')
    ## model
    path_model = os.path.join(project_root_dir, 'Model/ICI_predict.model.pt')
    ## model_run
    run_model = 'True'
    ## ig run
    run_ig = 'True'
    ## ig_fig
    ig_fig = './Results/ig/important_feature.pdf'
    ## output
    ig_output = './Results/ig/feature_importance.tsv'
    ## save log
    save_log = './Results/log/gnn_train_model.log'

    # Run Group for Patients
    if os.path.exists(km_group1) and os.path.exists(km_group2):
        df_os_1 = pd.read_table(km_group1)
        df_os_2 = pd.read_table(km_group2)
    else:
        df_os = pd.read_table(path_cli)
        df_os_1 = df_os[df_os.Type == 0]
        df_os_2 = df_os[df_os.Type == 1]
    print('Non-responder number: {}; Responder number: {}'.format(df_os_1.shape[0], df_os_2.shape[0]))
    cross_weight = torch.tensor([df_os_1.shape[0],df_os_2.shape[0]], dtype=torch.float32)
    cross_weight = torch.tensor([max(cross_weight)/x for x in cross_weight], dtype=torch.float32)

    # Read dataset
    print('[INFO] Load dataset...\n')
    dataset = torch.load(path_dataset)
    #train_labels, train_dataset, test_labels, test_dataset = split_dataset(dataset=dataset, df_os_1=df_os_1,df_os_2=df_os_2, test_perc=0.2)

    ###fold 决定test数据集占总数据集的五分之几
    fold = int(1)
    train_labels, train_dataset, test_labels, test_dataset = split_dataset_fold(dataset, df_os_1, df_os_2, folds=5 ,test_fold=fold)
    with open(save_log, 'a') as F:
        F.writelines('##Fold: {}\n'.format(fold))

    if run_model == "True":
        print('[INFO] Training model...\n')
        torch.backends.cudnn.enabled = False
        submodel_ = Pathway_Score().to(device)
        real_labels = train_labels
        dataset = train_dataset
        criterion = torch.nn.CrossEntropyLoss(weight=cross_weight)  # two class

        if os.path.exists(path_model):
            print('[INFO] Training (continue)\n')
            model = torch.load(path_model).to(device)
            for parma in model.parameters():
                parma.requires_grad = True
            optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.0001)
            criterion = torch.nn.CrossEntropyLoss(weight=cross_weight)
            for epoch in range(1):
                predict_label = train(train_labels, train_dataset, test_labels, test_dataset)
                torch.save(model, path_model + '.epoch{}.{}.pt'.format(epoch, fold))

            ig(path_model + '.epoch{}.{}.pt'.format(epoch, fold), test_labels, test_dataset, figname=ig_fig + 'fold{}'.format(fold), output=ig_output + 'fold{}'.format(fold))

        else:
            print('[INFO] Denova Training\n')
            model = Model(submodel=submodel_, dataset=dataset).to(device)
            loss_fun = torch.nn.BCEWithLogitsLoss()

            optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)
            for epoch in range(100):
                predict_label = train(train_labels, train_dataset, test_labels, test_dataset)
                torch.save(model, path_model + '.epoch{}.{}.pt'.format(epoch, fold))
            
            optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.0001)
            for epoch in range(50):
                predict_label = train(train_labels, train_dataset, test_labels, test_dataset)
                torch.save(model, path_model + '.epoch{}.{}.pt'.format(epoch+50, fold))

            
            ig(path_model + '.epoch{}.{}.pt'.format(epoch+50, fold), test_labels, test_dataset, figname=ig_fig + 'fold{}'.format(fold), output=ig_output + 'fold{}'.format(fold))

        # save model
        # torch.save(model, path_model)
    # ig("/home/PJLAB/liangbilin/Projects/DeepSurvial/Model/KIRC/KIRC.PathGNN.Fold{}.epoch249.pt".format(fold), '-', dataset, figname=ig_fig + '.fold{}.pdf'.format(fold), output=ig_output + '.fold{}.tsv'.format(fold))

    # if run_ig == "True":
    #     print('[INFO] Runing IG for important features.\n')
    #     ig(path_model, test_labels, test_dataset, figname=ig_fig, output=ig_output)

